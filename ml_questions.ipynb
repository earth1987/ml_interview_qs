{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcead1b8-1a00-4730-b26a-ed480259e426",
   "metadata": {},
   "source": [
    "# Machine learning interview questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995765b-6a31-4665-b796-6d82fa5d2b88",
   "metadata": {},
   "source": [
    "## Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce21714-c213-45df-80d4-e2768e36ce86",
   "metadata": {},
   "source": [
    "### 1. You are building a binary classifier for an unbalanced dataset (where 1 class is much rarer than the other, say 1% and 99%, respectively). How do you handle this situation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996f3f0-d762-4cc5-8385-dcf113903a79",
   "metadata": {},
   "source": [
    "Unbalanced classes can be dealt with in several ways.\n",
    "\n",
    "1. Can we get more data? Is the event inherently rare?\n",
    "2. Choose the appropriate performance metrics:\n",
    "   * Don't use accuracy\n",
    "   * Look at precision, recall, F1 score and the ROC curve\n",
    "     \n",
    "3. Apply resampling to the training data:\n",
    "   * Oversampling the minority class via bootstrapping\n",
    "   * Undersampling the majority class via bootstrapping\n",
    "     \n",
    "4) Generate synthetic examples for the training data\n",
    "   * SMOTE - creates synthetic examples of the minority class (random variations of instance attributes based on neighbours)\n",
    "     \n",
    "5) Ensemble models\n",
    "   * Apply boosting to reduce bias - higher weight is given to the minority class at each successive iteration\n",
    "     \n",
    "6) Design a custom cost function to penalise wrong classification of the rare class more than the majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c411f-64b2-47fb-b842-8733a1d74630",
   "metadata": {},
   "source": [
    "### 2. What are some differences you would expect in a model that minimises squared error versus a model that minimises absolute error? In which case would each error metric be appropriate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7ee68-af62-4919-98db-7d204893f314",
   "metadata": {},
   "source": [
    "$$MAE = \\frac{1}{N} \\Sigma_i^N (y_i - y_{pred})$$\n",
    "$$MSE = \\frac{1}{N} \\Sigma_i^N (y_i - y_{pred})^2$$\n",
    "<center> Where, N is the number of training samples </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579771e1-c7b9-434c-8a56-dded0add2c91",
   "metadata": {},
   "source": [
    "Key differences:\n",
    "* MSE is more sensitive to outliers as errors are squared before being averaged.\n",
    "* MSE is more efficient computationally as the gradient is easier to calculate during optimisation\n",
    "* Calculating the gradient of MAE requires linear programming (less efficient)\n",
    "\n",
    "Conclusion:\n",
    "* Use MAE if the model needs to be robust to outliers and computational efficiency isn't an issue (e.g. small training set)\n",
    "* Use MSE if the model doesn't need to be robust to outliers and computation time is an issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae621a1-30c8-4d8e-ae11-dff1daba0e36",
   "metadata": {},
   "source": [
    "### 3. When performing K-means clustering, how do you choose K?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b92178-4d9c-4265-bf97-c4ada7d60ab6",
   "metadata": {},
   "source": [
    "There is no perfect method for picking k (otherwise it would be a supervised problem).\n",
    "1. ***Business intuition***\n",
    "* Do you expect a certain number of clusters?\n",
    "* Visualise features within expected groups, do they behave similarly?\n",
    "<br>\n",
    "<br>\n",
    "2. ***Elbow method***\n",
    "* A few clusters should explain a lot of the variation in data \n",
    "* Plot the Within-Cluster-Sum of Squared Errors (WSS) for different values of k - at what point are there diminishing returns?\n",
    "* Calculation for each k:\n",
    "  * Fit k-mean clustering model\n",
    "  * Calculate the Squared Error for each point from the centroid of its cluster\n",
    "  * Sum the squared error across all points giving WSS\n",
    "  * Plot WSS versus k and choose k for which WSS becomes first starts to diminish\n",
    "<br>\n",
    "<br>\n",
    "3. ***Silhouette method***\n",
    "$$ Silhouette score = \\frac{(x-y)}{max(x,y)}$$\n",
    "<center> Where, x = mean distance to points of the nearest cluster & y = mean distance to points in the same cluster. Euclidian distance usually used. </center>\n",
    "* A silhouette score measures how similar a point is to its own cluster (cohesion) compared to other clusters (seperation)\n",
    "* The score ranges from -1 to + 1. A high value indicates a point is placed in the correct cluster\n",
    "* Calculation for each k:\n",
    "    * Calculate a silhouette for each point\n",
    "    * Plot a clustered bar chart showing scores for each point in their respective cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530f04d-2a33-495a-b67f-eab146b86b66",
   "metadata": {},
   "source": [
    "### 4. How can you make you models more robust to outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2551bb-0cee-43d7-88d3-b5b5939c1b3e",
   "metadata": {},
   "source": [
    "The first step is to try and understand why outliers occurred. Different steps can then be followed.\n",
    "1. ***Trimming***\n",
    "* If the points are truly anomalous, and not worth incorporating, they can be removed.\n",
    "* Risk losing information.\n",
    "<br>\n",
    "2. ***Winsorization***\n",
    "* Cap the data at a threshold\n",
    "* A 90% winorization:\n",
    "    * Cap the bottom 5% of values at the 5th percentile\n",
    "    * Cap the top 5% of values at the 95th percentile\n",
    "<br>\n",
    "3. ***Change the cost function***\n",
    "* The mean absolute error cost function is more robust to outliers than the mean squared error cost function (see above)\n",
    "<br>\n",
    "4. ***Add regularization***\n",
    "* L1 & L2 regularization reduce variance by minimising model weights\n",
    "<br>\n",
    "5. ***Transform the data***\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6be7a6-7b9c-4805-b78c-6c3ce3e2398f",
   "metadata": {},
   "source": [
    "### 5. Say that you are running a multiple linear regression and that you have reason to believe that several of the predictors are correlated. How will the results behave if several are indeed correlated? How would you deal with this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca319a26-ccbf-42f0-93c6-cace13e9395d",
   "metadata": {},
   "source": [
    "Two primary problems relate to uncertainty of feature importance\n",
    "1. ***P values are misleading***\n",
    "* Important variables may have higher, statistically insignificant, P-values (as importance split over correlated variables)\n",
    "<br>\n",
    "\n",
    "2. ***Coefficient estimates are unstable***\n",
    "* Coefficients vary depending on which variables included\n",
    "* Imprecise estimates of coefficients lead to broad confidence intervals (maybe including zero)\n",
    "<br>\n",
    "\n",
    "Solutions:\n",
    "1. ***Remove correlated predictors***\n",
    "* Remove variables clearly related to the other (e.g. X and 2X)\n",
    "* Use a latent (i.e. hidden) variable relating to correlated variables (e.g. speed replaces distance & time)\n",
    "<br>\n",
    "\n",
    "2. ***Combine correlated predictors***\n",
    "* Combine collerated variables using PCA\n",
    "* Calculate interaction terms - e.g product of the two that are correlated\n",
    "<br>\n",
    "\n",
    "3. ***Regularization***\n",
    "* Use L2 regularization (e.g. Ridge regression) to stabilise the size of the coefficients\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd6eda5-6728-41a2-84bf-b4e470ffb35e",
   "metadata": {},
   "source": [
    "### 6. Describe the motivation behind random forests. What are two ways in which they improve upon individual decision trees?\n",
    "\n",
    "Decision trees are prone to overfitting. Random forests are a type of ensemble learning.\n",
    "1. They reduce overfitting and therefore variance via bagging (bootstrap aggregating).\n",
    "2. Each consitituent decision tree is trained on a random subsample of the predictor variables. This decorrelates the trees meaning they are not equivalent and learn about other features of the data. Without it they would all prioritise the strong predictors.\n",
    "3. Random forests can be used to produce feature importance values [(see here)](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html). \n",
    "4. Easy to implement and fast to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a525e2-31b7-4ec8-aab0-470461c000e5",
   "metadata": {},
   "source": [
    "### 7. Given a large dataset of payment transactions, say we want to predict the likelihood of a given transaction being fraudulent. However, there are many rows with missing values for various columns. How would you deal with this?\n",
    "\n",
    "Approach in a series of steps:\n",
    "\n",
    "1. ***Characterise***\n",
    "* What features are missing data? Are missing values numerical or categorical?\n",
    "* Is it possible to use an additional data source to fill in the missing info?\n",
    "* Why is the data missing?\n",
    "    * *Missing completely at random (MCAR)*\n",
    "      - Randomly distributed across a given variable and the probability of a value being missing is unrelated to other variables.\n",
    "      - E.g. Skipping survey questions. Equipment malfunction. Data entry errors.\n",
    "        \n",
    "    * *Missing at random (MAR)*\n",
    "      - NOT randomly distributed as the probability of a value being missing is related to another variable.\n",
    "      - E.g. Systematic exclusions. Data not collected for a specific demographic.\n",
    "        \n",
    "    * *Not missing at random (NMAR)*\n",
    "       - Missing for reasons related to the values themselves.\n",
    "       - E.g. People not reporting their income **because** of the value. Fear of discrimination.\n",
    "\n",
    "2. ***Establish a baseline***\n",
    "* Build a baseline model - does it meet business goals?\n",
    "* Is the missing data problem?\n",
    "  * MCAR - Do the relevant features have predictive value?\n",
    "  * MAR - Is the missing data within a category where fraudulent transactions never occur?\n",
    "\n",
    "4. ***Impute missing data***\n",
    "* If the baseline model is not OK - impute!\n",
    "  * Mean/median value (simple but dosn't factor in other features and correlations)\n",
    "  * Use a nearest neighbour method to estimate a value based on other features\n",
    "    \n",
    "6. ***Check performance with imputed data***\n",
    "* Use cross validation to compare performance of model with/without imputed data. If there is no change - alter or remove missing data.\n",
    "\n",
    "Note: A performance increase would only be expected if the imputed features have predictive value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e220b-9289-4ddf-878f-cae286764089",
   "metadata": {},
   "source": [
    "### 8. Say you are running a simple logistic regression to solve a problem but find the results to be unsatisfactiory. What are some ways you might improve your model, or what other models might you look into using instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65653c3-2aae-4ca3-946e-eb03b343c3c6",
   "metadata": {},
   "source": [
    "***Model improvements***\n",
    "* Logistic regression models often have high bias - add more features\n",
    "* Make sure all features are normalised (so they don't dominate model performance)\n",
    "* Perform feature selection - removing features with no predictive value may reduce noise\n",
    "* Perform k-fold cross validation to optimise hyperparameters: e.g. choose a form of regularization to reduce overfitting\n",
    "\n",
    "***Alternative models***\n",
    "* Logistic regression provides a linear decision boundary.\n",
    "* The classes may not be linearly seperable, therefore try other classification methods:\n",
    "    * Support vector machine (SVM)\n",
    "    * Tree-based approaches\n",
    "    * Neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6844e98d-063a-4ef4-9cf7-bc79ef8c25bd",
   "metadata": {},
   "source": [
    "### 9. Say you were running a linear regression for a dataset but you accidentally duplicated every data point. What happens to your beta coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b26c08-081f-47e2-9426-3df30e780482",
   "metadata": {},
   "source": [
    "### 10. Compare and contrast gradient boosting and random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a9a5a-69a0-4c2c-9810-d31b96eac172",
   "metadata": {},
   "source": [
    "Both are forms of ensemble learning. Key differences:\n",
    "\n",
    "***Training***\n",
    "* Random forests rely on independant parallel training of decision trees using bootstrap aggregating (bagging)\n",
    "* Gradient boosting relies on sequential training of models where weak learners learn from the mistakes of preceding weak learners\n",
    "\n",
    "***Testing***\n",
    "$$\\hat{f}(x)= mode\\{\\hat{f}_1(x),\\hat{f}_2(x),1,...,\\hat{f}_m(x)\\}$$\n",
    "$$\\hat{f}(x)=\\frac{1}{M} \\sum_{m=1}^M\\hat{f}_m(x)$$\n",
    "<center> In random forests, the output of the trees is combined at test time via averaging or majority voting </center>\n",
    "\n",
    "$$\\hat{f}(x)=\\sum_{b=1}^B \\lambda \\hat{f}_b(x)$$\n",
    "<center> In boosting, models are combined sequentialy during training using a weighting. A final model is then applied at test time. </center>\n",
    "\n",
    "***Characteristics***\n",
    "* Gradient boosting is more prone to overfitting due to lack of independence and focus on mistakes\n",
    "* Gradient boosting hyperparameters are harder to tune\n",
    "* Gradient boosting can take longer to train overall due to sequential training of constituent models\n",
    "\n",
    "***Applications***\n",
    "* Gradient boosting is better for unbalanced datasets\n",
    "* Random forests are better for multi-class object detection with noisy data (e.g. computer vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937819fa-c571-4467-aa3f-6c752e1c4752",
   "metadata": {},
   "source": [
    "### 11. Say that DoorDash is launching in Singapore. For this new market, you want to predict the estimated time of arrival (ETA) for a delivery to reach a customer after an order has been placed on the app. From an earlier beta test in Singapore, there were 10,000 deliveries made. Do you have enough training data to create an accurate ETA model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2284edd5-33a9-40d0-9a1f-81155649ec49",
   "metadata": {},
   "source": [
    "\"Accurate\" is subjective. Therefore follow the below steps:\n",
    "\n",
    "1. ***Clarify what is \"good\" enough***\n",
    "* What will the prediction be used for? -> get context -> accuracy for order-driver matching may need to be higher than for customers\n",
    "* What errors are acceptable? -> for customers, better to overestimate delivery than underestimate\n",
    "* Benchmark performance for ETA -> establish accuracy provided in other markets\n",
    "  \n",
    "2. ***Assess baseline performance***\n",
    "* Develop a baseline model using the 10,000 deliveries\n",
    "* This is a regression problem therefore try:\n",
    "  * Multi-linear regression: preperation time + distance\n",
    "  * Assess performance using RMSE, MAE, R2\n",
    "\n",
    "3. ***Determine how additional data improves accuracy***\n",
    "* Choose an evaluation metric (e.g. R2) and build learning curves to assess how performance changes with increasing % of data\n",
    "* If the learning curve begins to plateau then more data might not be required - focus on optimisation (i.e. feature selection, regularization etc.)\n",
    "\n",
    "If more data is required as performance isn't good enough. Follow the below steps:\n",
    "\n",
    "1. ***Assess features***\n",
    "* Can we add additional features (e.g. traffic patterns, supply & demand)\n",
    "* Are there are almost as many or more featurs than data points, if so the model will be prone to overfitting - apply PCA or feature selection\n",
    "\n",
    "2. ***Alternative model***\n",
    "* Do alternative models cope better with smaller training datasets?\n",
    "\n",
    "3. ***Assess impact***\n",
    "* Is the less accurate prediction a true launch blocker?\n",
    "* If not, launch in the new market and retrain the model using the generated data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nl2vis",
   "language": "python",
   "name": "nl2vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
