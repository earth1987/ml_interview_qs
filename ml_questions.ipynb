{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcead1b8-1a00-4730-b26a-ed480259e426",
   "metadata": {},
   "source": [
    "# Machine learning interview questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce21714-c213-45df-80d4-e2768e36ce86",
   "metadata": {},
   "source": [
    "1. **You are building a binary classifier for an unbalanced dataset (where 1 class is much rarer than the other, say 1% and 99%, respectively). How do you handle this situation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996f3f0-d762-4cc5-8385-dcf113903a79",
   "metadata": {},
   "source": [
    "Unbalanced classes can be dealt with in several ways.\n",
    "\n",
    "1. Can we get more data? Is the event inherently rare?\n",
    "2. Choose the appropriate performance metrics:\n",
    "   * Don't use accuracy\n",
    "   * Look at precision, recall, F1 score and the ROC curve\n",
    "     \n",
    "3. Apply resampling to the training data:\n",
    "   * Oversampling the minority class via bootstrapping\n",
    "   * Undersampling the majority class via bootstrapping\n",
    "     \n",
    "4) Generate synthetic examples for the training data\n",
    "   * SMOTE - creates synthetic examples of the minority class (random variations of instance attributes based on neighbours)\n",
    "     \n",
    "5) Ensemble models\n",
    "   * Apply boosting to reduce bias - higher weight is given to the minority class at each successive iteration\n",
    "     \n",
    "6) Design a custom cost function to penalise wrong classification of the rare class more than the majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c411f-64b2-47fb-b842-8733a1d74630",
   "metadata": {},
   "source": [
    "2. **What are some differences you would expect in a model that minimises squared error versus a model that minimises absolute error? In which case would each error metric be appropriate?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7ee68-af62-4919-98db-7d204893f314",
   "metadata": {},
   "source": [
    "$$MAE = \\frac{1}{N} \\Sigma_i^N (y_i - y_{pred})$$\n",
    "$$MSE = \\frac{1}{N} \\Sigma_i^N (y_i - y_{pred})^2$$\n",
    "<center> Where, N is the number of training samples </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579771e1-c7b9-434c-8a56-dded0add2c91",
   "metadata": {},
   "source": [
    "Key differences:\n",
    "* MSE is more sensitive to outliers as errors are squared before being averaged.\n",
    "* MSE is more efficient computationally as the gradient is easier to calculate during optimisation\n",
    "* Calculating the gradient of MAE requires linear programming (less efficient)\n",
    "\n",
    "Conclusion:\n",
    "* Use MAE if the model needs to be robust to outliers and computational efficiency isn't an issue (e.g. small training set)\n",
    "* Use MSE if the model doesn't need to be robust to outliers and computation time is an issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae621a1-30c8-4d8e-ae11-dff1daba0e36",
   "metadata": {},
   "source": [
    "3. **When performing K-means clustering, how do you choose K?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b92178-4d9c-4265-bf97-c4ada7d60ab6",
   "metadata": {},
   "source": [
    "There is no perfect method for picking k (otherwise it would be a supervised problem).\n",
    "1. *Business intuition*\n",
    "* Do you expect a certain number of clusters?\n",
    "* Visualise features within expected groups, do they behave similarly?\n",
    "<br>\n",
    "<br>\n",
    "2. *Elbow method*\n",
    "* A few clusters should explain a lot of the variation in data \n",
    "* Plot the Within-Cluster-Sum of Squared Errors (WSS) for different values of k - at what point are there diminishing returns?\n",
    "* Calculation for each k:\n",
    "  * Fit k-mean clustering model\n",
    "  * Calculate the Squared Error for each point from the centroid of its cluster\n",
    "  * Sum the squared error across all points giving WSS\n",
    "  * Plot WSS versus k and choose k for which WSS becomes first starts to diminish\n",
    "<br>\n",
    "<br>\n",
    "3. *Silhouette method*\n",
    "$$ Silhouette score = \\frac{(x-y)}{max(x,y)}$$\n",
    "<center> Where, x = mean distance to points of the nearest cluster & y = mean distance to points in the same cluster. Euclidian distance usually used. </center>\n",
    "* A silhouette score measures how similar a point is to its own cluster (cohesion) compared to other clusters (seperation)\n",
    "* The score ranges from -1 to + 1. A high value indicates a point is placed in the correct cluster\n",
    "* Calculation for each k:\n",
    "    * Calculate a silhouette for each point\n",
    "    * Plot a clustered bar chart showing scores for each point in their respective cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530f04d-2a33-495a-b67f-eab146b86b66",
   "metadata": {},
   "source": [
    "4. **How can you make you models more robust to outliers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2551bb-0cee-43d7-88d3-b5b5939c1b3e",
   "metadata": {},
   "source": [
    "The first step is to try and understand why outliers occurred. Different steps can then be followed.\n",
    "1. *Trimming*\n",
    "* If the points are truly anomalous, and not worth incorporating, they can be removed.\n",
    "* Risk losing information.\n",
    "<br>\n",
    "2. *Winsorization*\n",
    "* Cap the data at a threshold\n",
    "* A 90% winorization:\n",
    "    * Cap the bottom 5% of values at the 5th percentile\n",
    "    * Cap the top 5% of values at the 95th percentile\n",
    "<br>\n",
    "3. *Change the cost function*\n",
    "* The mean absolute error cost function is more robust to outliers than the mean squared error cost function (see above)\n",
    "<br>\n",
    "4. *Add regularization*\n",
    "* L1 & L2 regularization reduce variance by minimising model weights\n",
    "<br>\n",
    "5. *Transform the data*\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6be7a6-7b9c-4805-b78c-6c3ce3e2398f",
   "metadata": {},
   "source": [
    "5. **Say that you are running a multiple linear regression and that you have reason to believe that several of the predictors are correlated. How will the results behave if several are indeed correlated? How would you deal with this problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca319a26-ccbf-42f0-93c6-cace13e9395d",
   "metadata": {},
   "source": [
    "Two primary problems relate to uncertainty of feature importance\n",
    "1. *P values are misleading*\n",
    "* Important variables may have higher, statistically insignificant, P-values (as importance split over correlated variables)\n",
    "<br>\n",
    "\n",
    "2. *Coefficient estimates are unstable*\n",
    "* Coefficients vary depending on which variables included\n",
    "* Imprecise estimates of coefficients lead to broad confidence intervals (maybe including zero)\n",
    "<br>\n",
    "\n",
    "Solutions:\n",
    "1. *Remove correlated predictors*\n",
    "* Remove variables clearly related to the other (e.g. X and 2X)\n",
    "* Use a latent (i.e. hidden) variable relating to correlated variables (e.g. speed replaces distance & time)\n",
    "<br>\n",
    "\n",
    "2. *Combine correlated predictors*\n",
    "* Combine collerated variables using PCA\n",
    "* Calculate interaction terms - e.g product of the two that are correlated\n",
    "<br>\n",
    "\n",
    "3. *Regularization*\n",
    "* Use L2 regularization (e.g. Ridge regression) to stabilise the size of the coefficients\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nl2vis",
   "language": "python",
   "name": "nl2vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
